{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbb50468-b0ac-4f7e-9fad-72f0af5fda20",
   "metadata": {},
   "source": [
    "<b> Chapter 4 is a technical chapter which will go over the mathematics behind some of the machine learning models that have been used so far.  I will be focusing on the linear algebra definitions and applications as they more succinctly embody the theories and calculations </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21427fd-a99e-40fa-b2ba-64cf906ee565",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab7d0da-7a23-4517-9be1-fd0f0c60f613",
   "metadata": {},
   "source": [
    "<b> Simply put linear regression is a weighted average of features and a scalar bias.  The weights are bias are chosen based off the minimization of a cost function.  The most common cost function for linear regressions is Mean Squared Error (MSE) which is rooted (RMSE) when comparing across multiple models.  The reason MSE is used is because the derivative is much simpler to compute and requires significantly less computational power than the rooted version.  Since rooting the function simply scales it, selecting MSE to minimize has the same end result as selected RMSE to minimize.  This is true in general for any cost or reward function and it is encouraged to use the form of the cost function which minimizes computational effort. </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046ac62a-356f-4853-b450-9ad60e81d47d",
   "metadata": {},
   "source": [
    "## The Normal Equation\n",
    "\n",
    "#### ${\\hat{\\theta}}$ = $(\\mathbf{X^T}\\mathbf{X})^{-1} \\mathbf{X^T} \\mathbf{y}$\n",
    "\n",
    "In this equation:\n",
    "\n",
    "${\\hat{\\theta}}$ is the value of $\\theta$ that minimizes the cost function\n",
    "<br>\n",
    "$\\mathbf{y}$ is the vector of target values\n",
    "<br>\n",
    "$\\mathbf{X}$ is a matrix of features with a bias column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d82d41c3-93a2-48f0-a45c-8ab7fedca06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.99047872],\n",
       "       [3.01480337]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' Generate some data to validate the above expression'\n",
    "import numpy as np\n",
    "\n",
    "X = 2 * np.random.rand(100, 1)\n",
    "y = 4 + 3 * X + np.random.randn(100, 1) # mx + b : 3x + 4 + noise\n",
    "\n",
    "' Introduce the constant bias'\n",
    "X_b = np.c_[np.ones((100, 1)), X] # m x n matrix with column of 1's and column of X values\n",
    "\n",
    "' Apply the normal equation'\n",
    "theta_best = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)\n",
    "theta_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83b5e8a-2fa3-4ac2-a43a-90d5437aba31",
   "metadata": {},
   "source": [
    "<b> The bias chosen was 4 and the weight was 3.  The gaussian noise introduced makes it impossible to get these exact values but the derived values are almost perfect.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e937627-9114-44dc-bc48-36dce03a5618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.99047872],\n",
       "       [10.02008547]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' Make some predictions'\n",
    "X_new = np.array([[0], [2]])\n",
    "X_new_b = np.c_[np.ones((2, 1)), X_new]\n",
    "\n",
    "y_predict = X_new_b.dot(theta_best)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2064678e-404e-46a9-801e-2fa2f0d5c217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x266d45fa3a0>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "' Plot the raw data and the best fit predictions'\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(X, y)\n",
    "plt.plot(X, X_b.dot(theta_best), color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4ccf1d9-8629-46c2-bfc0-f8c58a01a278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias:  [3.99047872] Coefficient:  [[3.01480337]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 3.99047872],\n",
       "       [10.02008547]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' Performing linear regression with sklearn is very simple'\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X, y)\n",
    "\n",
    "print('Bias: ', lin_reg.intercept_, 'Coefficient: ', lin_reg.coef_)\n",
    "\n",
    "lin_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c25a93-aaa3-431c-9225-86f88a855c8e",
   "metadata": {},
   "source": [
    "<b> A caveat for inverted matrices is that they require a non-zero determinant.  This isn't always the case.  A work-around is the Moore-Penrose Inverse aka the pseudoinverse.  This utilizes Singular Value Decomposition to generate an equivalent matrix which is always invertible.  This method is also more computationally efficient. Sklearn ueses this method natively </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e7cfda-4dbb-4ef9-950f-5a0cf8a26f10",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb4bddd-c559-4994-b25c-34e4a5442fda",
   "metadata": {},
   "source": [
    "<b> Gradient Descent outperforms sklearn and the Normal Equation when the dataset is extremely large (100,000+ features).  </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab888f9-f3d6-4d59-b2fb-3be5f936d97f",
   "metadata": {},
   "source": [
    "<b> General notes about gradient descent </b>\n",
    "* Tweaks parameters iteratively in order to minimize a cost function\n",
    "* Not all cost functions are convex.  As such, one hurdle for gradient descent is overcoming local minima and plateaus\n",
    "* The learning rate is the primary parameter for correctly finding the absolute minima.  Too high and the optimizer will diverge and never find a minima. Too low and it will stop too soon at a local minima\n",
    "* Because a convex function has exactly 1 minima they are ideal. If possible, transform the cost function such that its transformation is convex.\n",
    "* Scaling all features has an enormous impact on how long it takes for the optimizer to find the mininma. \n",
    "* Gradient descent utilizes the properties of partial derivatives.  As such, a less complex derivative is arguably more important than a convex, continuous function.  Both is ideal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92247245-a5f5-4f49-875b-5b38ccfb5a9f",
   "metadata": {},
   "source": [
    "## Gradient Vector of the Cost Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e1e88d-22af-425a-a0ac-fb0cce053898",
   "metadata": {},
   "source": [
    "#### $\\nabla_{\\boldsymbol\\theta}MSE(\\boldsymbol\\theta) = \\frac{2}{m}\\mathbf{X}^{T}(\\mathbf{X}\\boldsymbol\\theta - \\mathbf{y})$\n",
    "\n",
    "<br>\n",
    "\n",
    "<b> Notice that this formula computes over the full training set X at each step.  The batch size here is 1 and as a result the training time on large datasets will be greatly impacted.  There are other ways to do this involving larger batch sizes which will be discussed later<b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bea2681-4f81-475d-9831-59f1d06babe9",
   "metadata": {},
   "source": [
    "## Gradient Descent Step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9519d015-40e4-47e5-a810-65afd9b4c19b",
   "metadata": {},
   "source": [
    "#### $\\boldsymbol\\theta^{(next step)} = \\boldsymbol\\theta - \\eta\\nabla_{\\boldsymbol\\theta}MSE(\\boldsymbol\\theta)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a39c430-fa06-4cc3-8f06-0573df641bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.99047872]\n",
      " [3.01480337]] \n",
      " \n",
      " This is exactly what the Normal Equation yielded\n"
     ]
    }
   ],
   "source": [
    "' Validate the above expressions'\n",
    "eta = 0.1  #learning rate\n",
    "n_iterations = 1000\n",
    "m = 100\n",
    "\n",
    "theta = np.random.randn(2, 1) # random initialization\n",
    "\n",
    "for iteration in range(n_iterations):\n",
    "    gradients = 2/m * X_b.T.dot(X_b.dot(theta) - y)\n",
    "    theta = theta - eta*gradients\n",
    "    \n",
    "print (theta, '\\n', '\\n', 'This is exactly what the Normal Equation yielded')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20d813c-16f4-4dd3-8b98-baa458f70d45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
