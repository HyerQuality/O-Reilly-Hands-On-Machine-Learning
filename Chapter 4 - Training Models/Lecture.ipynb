{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbb50468-b0ac-4f7e-9fad-72f0af5fda20",
   "metadata": {},
   "source": [
    "<b> Chapter 4 is a technical chapter which will go over the mathematics behind some of the machine learning models that have been used so far.  I will be focusing on the linear algebra definitions and applications as they more succinctly embody the theories and calculations </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21427fd-a99e-40fa-b2ba-64cf906ee565",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab7d0da-7a23-4517-9be1-fd0f0c60f613",
   "metadata": {},
   "source": [
    "<b> Simply put linear regression is a weighted average of features and a scalar bias.  The weights are bias are chosen based off the minimization of a cost function.  The most common cost function for linear regressions is Mean Squared Error (MSE) which is rooted (RMSE) when comparing across multiple models.  The reason MSE is used is because the derivative is much simpler to compute and requires significantly less computational power than the rooted version.  Since rooting the function simply scales it, selecting MSE to minimize has the same end result as selected RMSE to minimize.  This is true in general for any cost or reward function and it is encouraged to use the form of the cost function which minimizes computational effort. </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046ac62a-356f-4853-b450-9ad60e81d47d",
   "metadata": {},
   "source": [
    "# The Normal Equation\n",
    "\n",
    "${\\hat{\\theta}}$ = $(\\mathbf{X^T}\\mathbf{X})^{-1} \\mathbf{X^T} \\mathbf{y}$\n",
    "\n",
    "In this equation:\n",
    "\n",
    "${\\hat{\\theta}}$ is the value of $\\theta$ that minimizes the cost function\n",
    "<br>\n",
    "$\\mathbf{y}$ is the vector of target values\n",
    "<br>\n",
    "$\\mathbf{X}$ is a matrix of features with a bias column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d82d41c3-93a2-48f0-a45c-8ab7fedca06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.09113012],\n",
       "       [2.96427959]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' Generate some data to validate the above expression'\n",
    "import numpy as np\n",
    "\n",
    "X = 2 * np.random.rand(100, 1)\n",
    "y = 4 + 3 * X + np.random.randn(100, 1)\n",
    "\n",
    "' Introduce the constant bias'\n",
    "X_b = np.c_[np.ones((100, 1)), X]\n",
    "\n",
    "' Apply the normal equation'\n",
    "theta_best = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)\n",
    "theta_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83b5e8a-2fa3-4ac2-a43a-90d5437aba31",
   "metadata": {},
   "source": [
    "<b> The bias chosen was 4 and the weight was 3.  The gaussian noise introduced makes it impossible to get these exact values but the derived values are almost perfect.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e937627-9114-44dc-bc48-36dce03a5618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.09113012],\n",
       "       [10.0196893 ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' Make some predictions'\n",
    "X_new = np.array([[0], [2]])\n",
    "X_new_b = np.c_[np.ones((2, 1)), X_new]\n",
    "\n",
    "y_predict = X_new_b.dot(theta_best)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2064678e-404e-46a9-801e-2fa2f0d5c217",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
