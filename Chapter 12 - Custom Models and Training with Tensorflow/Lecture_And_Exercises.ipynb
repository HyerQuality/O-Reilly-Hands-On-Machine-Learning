{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0dd750b2-bd12-401e-8f93-480021a8364e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8094e3-839a-4ec6-b7ce-4cfb4e2c6a95",
   "metadata": {},
   "source": [
    "# A Quick Tour of Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1061a1ee-39cf-4ecf-a629-809d3aaf7653",
   "metadata": {},
   "source": [
    "Here's a summary of what TensorFlow has to offer:\n",
    "\n",
    "1. Its core is very similar to NumPy, but with GPU support\n",
    "2. It supports distributed computing (across multiple devices and servers)\n",
    "3. It includes a kind of just-in-time (JIT) compiler that allows it to optimize computations for speed and memory usage. It works by extracting the *computation graph* from a Python function, then optimizing it (e.g. by pruning unused nodes), and finally running it efficiently (e.g. by automatically running independent operations in parallel.)\n",
    "4. Computation graphs can be exported to a portable format so you can train a TensorFlow model in on environment (e.g. using Python on Linux) and run it in another (e.g. using Java on an Android device)\n",
    "5. It implements autodiff (see Chapter 10 and Appendix D) and provides some excellent optimizers, such as RMSProp and Nadam (see Chapter 11), so you can easily minimize all sorts of loss functions.\n",
    "\n",
    "TensorFlow offers many more features built on top of these core features: the most important is of course tf.keras, but it also has data loading and preprocessing ops, image processing ops, signal processing ops, and more. \n",
    "\n",
    "As you may know, GPUs can dramatically speed up computations by splitting them into many smaller chunks and running them in parallel across many GPU threads. TPUs are even faster: they are custom ASIC chips built specifically for Deep Learning operations.\n",
    "\n",
    "There's even more to the TensorFlow library:\n",
    "1. TensorBoard - for visualization\n",
    "2. TensorFlow Extended (TFX) - a set of libraries built by Google to productionize TensorFlow projects. It includes tools for data validation, preprocessing, model analysis, and serving.\n",
    "3. TensorFlow Hub - provides a way to easily download and reuse pretrained neural networks. You can also get many neural network architectures, some of them pretrained, in TensorFlows *model garden*\n",
    "4. TensorFlow Resources - contains TensorFlow-based projects. You will find hundreds of TensorFlow projects on GitHub, so it is often easy to find existing coded for whatever you are trying to do.\n",
    "\n",
    "More and more ML papers are released along with their implementations, and sometimes even with pretrained models. Check out https://paperswithcode.com/ to easily find them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e335b5-237e-4827-893c-3dd501ceadd4",
   "metadata": {},
   "source": [
    "## Using Tensorflow like NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c34405f-9bf3-4bb4-8744-4f35002e284b",
   "metadata": {},
   "source": [
    "TensorFlow's API revolves around tensors. A tensor is usually a multidimensional array, b ut it can also hold a scaler. Let's see how to create and manipulate them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d11df0-0b3e-4f20-a7c5-04b3c321aeed",
   "metadata": {},
   "source": [
    "### Tensors and Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bc868b54-9590-4cbf-97b7-acd77adda999",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       " array([[1., 2., 3.],\n",
       "        [4., 5., 6.]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=42>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant([[1., 2., 3.], [4., 5., 6]]), tf.constant(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "406d9184-1e5f-4dce-9238-5550579f076a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([2, 3]), tf.float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just like an ndarray, a tf.Tensor has a shape and a data type\n",
    "t = tf.constant([[1., 2., 3.], [4., 5., 6]])\n",
    "t.shape, t.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fe9c3bae-e3dd-4924-b2dc-bdbad945451e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2., 3.],\n",
       "       [5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexing works much like in Numpy\n",
    "t[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "510cecb7-cfe4-4d4a-a1e1-2b841d15e68b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[2.],\n",
       "       [5.]], dtype=float32)>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[..., 1, tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "de757633-60eb-4bd0-8150-e69bafc2bc17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       " array([[11., 12., 13.],\n",
       "        [14., 15., 16.]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       " array([[ 1.,  4.,  9.],\n",
       "        [16., 25., 36.]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       " array([[14., 32.],\n",
       "        [32., 77.]], dtype=float32)>)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# More importantly, all sorts of tensor operations are available\n",
    "t + 10, tf.square(t), t @ tf.transpose(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6115fa8-4080-4aae-84d9-0f69d5c8e872",
   "metadata": {},
   "source": [
    "You will find all the basic math operations you need (tf.add(), tf.multiply(), tf.square(), tf.exp(), tf.sqrt(), etc.) and most operations that you can find in Numpy (e.g. tf.reshape(), tf.squeeze(), tf.tile()). Some functions have a different name than Numpy; for instance, tf.reduce_mean(), tf.reduce_sum(), tf.reduce_max(), and tf.math.log() are the equivalent of np.mean(), np.sum(), np.max() and np.log().\n",
    "\n",
    "When the name differs, there is often a good reason for it. For example, in TensorFlow you must write tf.transpose(t); you cannot use write t.T like in NumPy. The reason is that the tf.transpose() function does not do exactly the same thing as Numpy's T attribute: in TensorFlow, a new tensor is created with its own copy of the transposed data, whlie in Numpy, t.T is just a transposed view of the same data. \n",
    "\n",
    "Similarly, the tf.reduce_sum() operation is named this way because its GPU kernel (i.e. GPU implementation) uses a reduce algorithm that does not guarantee the order in which the elements are added: because 32-bit floats have limited precision, the result may change ever so slightly every time you call this operation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f364299-3332-4359-9eb4-2ac570fbcf9b",
   "metadata": {},
   "source": [
    "### Tensors and NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "30a817cf-7af0-45a0-b384-d5ccc825f86b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=float64, numpy=array([2., 4., 5.])>,\n",
       " array([[1., 2., 3.],\n",
       "        [4., 5., 6.]], dtype=float32))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensors play nice with Numpy\n",
    "a = np.array([2., 4., 5.])\n",
    "tf.constant(a), t.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "202ecb66-c823-4796-afb5-fc06cc69bc6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=float64, numpy=array([ 4., 16., 25.])>,\n",
       " array([[ 1.,  4.,  9.],\n",
       "        [16., 25., 36.]], dtype=float32))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(a), np.square(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739eeac0-245a-47d6-8797-7852e24b12ca",
   "metadata": {},
   "source": [
    "Notice that NumPy uses 64-bit precision by default, while TensorFlow uses 32-bit. This is because 32-bit precision is generally more than enough for neural networks, plus it runs faster and uses less RAM. So when you create a tensor from a NumPy array, make sure to set dtype=tf.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447f2188-6283-4f2d-9569-1d0c0777aace",
   "metadata": {},
   "source": [
    "### Type Conversions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41c2c85-4dae-4578-98f8-7bd6e9c716f8",
   "metadata": {},
   "source": [
    "Type conversions can significantly hurt performance, and they can easily go unnoticed when they are done automatically. To avoid this, TensorFlow does not perform any type conversions automatically: it just raises an exception if you try to execute an operation on tensors with incompatible types. This may be a bit annoying at first, but remember that it's for a good cause! And of course you can use tf.cast() when you really need to convert types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "12479a6a-4534-4d4d-a132-40bf0de1b79a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' InvalidArgumentError: cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:AddV2]'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of Exception\n",
    "# tf.constant(2.) + tf.constant(40)\n",
    "\n",
    "' InvalidArgumentError: cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:AddV2]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bf6a2e16-ff6c-4105-b80d-0d1cdb393f0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=42.0>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example casting variables as the correct type\n",
    "t2 = tf.constant(40., dtype=tf.float64)\n",
    "tf.constant(2.0) + tf.cast(t2, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b486de6-c2ab-48b8-bddc-84b3389f864c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155f2296-d01a-4bf3-a854-811cfd16dc33",
   "metadata": {},
   "source": [
    "The tf.Tensor values we've seen so far are immutable: you cannot modify them. For mutable tf.Tensor values we need tf.Variable. A tf.Variable acts much like a tf.Tensor: you can perform the same operations with it, it plays nicely with NumPy as well, and it is just as picky with types. But it can also be modified in place using the assign() method (or assign_add() or assign_sub(), which increment or decrement the variable by the given value).\n",
    "\n",
    "In practice you will rarely have to create variables manually, since Keras provides an add_weight() method that will take care of it for you, as we will see. Moreover, model parameters will generally be updated directly by the optimizers, so you will rarely need to update variables manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "bbdf1d29-890b-46c8-8673-e6a9f029797d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variable examples\n",
    "v = tf.Variable([[1., 2., 3.], [4., 5., 6.]])\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6e1218e7-a77c-4dc4-b876-4778b8f39b8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2.,  4.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.assign(2 * v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5d058338-e8bb-4545-a859-33844f7a7e94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2., 42.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[0, 1].assign(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1831af6e-ba10-4ecd-999d-ceb2bcb1e3db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2., 42.,  0.],\n",
       "       [ 8., 10.,  1.]], dtype=float32)>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[:, 2].assign([0., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "00a610e6-a9f7-4d56-b07f-e20a24774535",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[100.,  42.,   0.],\n",
       "       [  8.,  10., 200.]], dtype=float32)>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.scatter_nd_update(\n",
    "    indices=[[0, 0], [1, 2]],\n",
    "    updates=[100., 200.]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9ca8c9-a1d1-45ed-b2d8-d585b31c5180",
   "metadata": {},
   "source": [
    "## Other Data Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5074b7fc-29fb-4ad0-a51a-47d641cb7c80",
   "metadata": {},
   "source": [
    "TensorFlow supports several other data structures, including the following:\n",
    "\n",
    "1. Sparse tensors (tf.SparseTensor)\n",
    "> Efficiently represent tensors containing mostly zeros. The tf.sparse package contains operations for sparse tensors.\n",
    "\n",
    "2. Tensor arrays (tf.TensorArray)\n",
    "> Are lists of tensors. They have a fixed size by default but can optionally be made dynamic. All tensors they contain must have the same shape and data type.\n",
    "\n",
    "3. Ragged tensors (tf.RaggedTensor)\n",
    "> Represent static lists of lists of tensors, where every tensor has the same shape and data type. The tf.ragged package contains operations for ragged tensors.\n",
    "\n",
    "4. String tensors\n",
    "> Are regular tensors of type tf.string. These represent byte strings, not Unicode strings, so if you create a string tensor using a Unicode string (e.g., a regular Pythong 3 string like \"coffee\"), then it will get encoded to UTF-8 automatically. Alternatively, you can represent Unicode strings using tensors of type tf.int32, where each item represents a Unicode code point (e.g., [99, 97, 102, 233]). The tf.strings package (with an s) contains ops for byte strings and Unicode strings (and to convert one into the other). It's important to note that a tf.string is atomic, meaning that its length does not appear in the tensor's shape. Once you convert it to a Unicode tensor (i.e. a tensor of type tf.int32 holding Unicode code points), the length appears in the shape.\n",
    "\n",
    "5. Sets\n",
    "> Are represented as regular tensors (or sparse tensors). For example, tf.constant([[1, 2], [3, 4]]) represents the two sets {1, 2} and {3, 4}. More generally, each set is represented by a vector in the tensor's last axis. You can manipulate sets using operations from the tf.sets package.\n",
    "\n",
    "6. Queues\n",
    "> Store tensors across multiple steps. TensorFlow offers various kinds of queues, these classes are all in the tf.queue package:\n",
    ">    1. Simple First In, First Out (FIFO) queues (FIFOQueue)\n",
    "    2. Queues that can prioritize some items (PriorityQueue)\n",
    "    3. Queues that shuffle their items (RandomShuffleQueue)\n",
    "    4. Queus that batch items of different shapes by padding (PaddingFIFOQueue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3724d785-505f-40ce-af62-7663c438a2f0",
   "metadata": {},
   "source": [
    "# Customizing Models and Training Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412a3ae6-0fcf-45f7-8dde-9ba895c441b8",
   "metadata": {},
   "source": [
    "## Custom Loss Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9cd3b4-2e28-42e5-b6ef-7a7cbd1f45ed",
   "metadata": {},
   "source": [
    "Suppose you want to train a regression model, but your training set is a bit noisy. Of course, you start by trying to clean up your dataset by removing or fixing the outliers, but that turns out to be insufficient; the dataset is still noisy. Which loss function should you use? The mean squared error might penalize large errors too much and cause your model to be imprecise. The mean absolute error would not penalize outliers as much, but training might take a while to converge, and the trained model might not be very precise. This is probably a good time to use the Huber loss (introduced in Chapter 10) instead of the good old MSE. The Huber loss is not currently part of the official Keras API, but it is available in tf.keras (just use an instance of the keras.losses.Huber class). But let's pretend it's not there: implementing it is easy as pie! Just create a function that takes the labels and predictions as arguments, and use TensorFlow operations to compute every instance's loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b77a284c-0136-4792-bd5f-6049624c2b91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' For best performance you should always vectorize implementations, as in this example. Moreover, if you want to benefit from TensorFlows graph features, you should use only TensorFlow operations'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def huber_fn(y_true, y_pred):\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tf.abs(error) < 1\n",
    "    squared_loss = tf.square(error) / 2\n",
    "    linear_loss = tf.abs(error) - 0.5\n",
    "    return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "\n",
    "' For best performance you should always vectorize implementations, as in this example. Moreover, if you want to benefit from TensorFlows graph features, you should use only TensorFlow operations'\n",
    "\n",
    "# To use with a model\n",
    "# model.compile(loss=huber_fn, optimizer='nadam')\n",
    "# model.fit(X_train, y_train, [...])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421320a9-f86b-4df8-a078-86dd1550015d",
   "metadata": {},
   "source": [
    "It is also preferable to return a tensor containing one loss per instance, rather than returning the mean loss. This way, Keras can apply class weights or sample weights when requested (Chapter 10). Now you can use this loss when you compile the Keras model, then train your model, and that's it! But what happens to this custom loss when you save the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ee870a-65d5-4ce4-95da-594d993113b4",
   "metadata": {},
   "source": [
    "## Saving and Loading Models That Contain Custom Components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bfc6dd-df75-43ef-8085-2e3fca01f267",
   "metadata": {},
   "source": [
    "Saving a model containing a custom loss function works fine, as Keras saves the name of the function. When you load a model containing custom objects, you need to map the names to the objects, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a7e93857-dace-4918-b312-8d8e15976c79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = tf.keras.models.load_model('model_with_custom_loss.h5', custom_objects={'huber_fn': huber_fn})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fcbede-15e3-4dba-b3a1-a3ad0af022ac",
   "metadata": {},
   "source": [
    "With the current implementation, any error between -1 and 1 is considered \"small\". But what if you want a different threshold? You can solve this by creating a subclass of the keras.losses.Loss class, and then implementing its get_config() method, as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "1c7d0aac-b586-421c-920f-0a21cedd921c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class HuberLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        self.threshold = threshold\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def call(self, y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < self.threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss = self.threshold * tf.abs(error) - self.threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, 'threshold': self.threshold}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e9559f-8ca9-4677-8c0d-a185775f01e5",
   "metadata": {},
   "source": [
    "The Keras API currently only specifies how to use subclassing to define layers, models, callbacks, and regularizers. If you build other components (such as losses, metrics, initializers, or constraints) using subclassing, they may not be portable to other Keras implementations. It's likely that the Keras API will be updated to specify subclassing for all these components as well.\n",
    "\n",
    "That said, let's walk through the code above:\n",
    "\n",
    "1. The constructor accepts **kwargs** and passes them to the parent constructor, which handles standard hyperparameters: the name of the loss and the reduction algorithm to use to aggregate the individual instance losses. By default, it is 'sum_over_batch_size', which means that the loss will be the sum of the instance losses, weighted by the sample weights, if any, and divided by the batch size (not by the sum of weights, so this is *not* the weighted mean). It would not be a good idea to use a weighted mean: if you did, then two instances with the same weight but in different batches would have a different impact on training, depending on the total weight of each batch. Other possible values are 'sum' and 'None'.\n",
    "\n",
    "2. The call() method takes the labels and predictions, computes all the instance losses, and returns them.\n",
    "\n",
    "3. The get_config() method returns a dictionary mapping each hyperparameter name to its value. It first calls the parent classes get_config() method, then adds the new hyperparameters to this dictionary.\n",
    "\n",
    "You can then use any instance of this class when you compile the model. When you save the model, the threshold will be saved along with it; and when you load the model, you just need to map the class name to the class itself, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d6efb2f7-fde2-4614-adf0-7216efaaf60d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.compile(loss=HuberLoss(threshold=2.), optimizer='nadam')\n",
    "# model = tf.keras.models.load_model('my_model_with_custom_loss_class.h5', custom_objects={'HuberLoss': HuberLoss})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5833e170-acc5-4c35-886c-172da359e5e1",
   "metadata": {},
   "source": [
    "## Custom Activation Functions, Initializers, Regularizers, and Contstraints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729a6519-dbe4-4349-94b2-e51f29151cf6",
   "metadata": {},
   "source": [
    "Most Keras functionalities, such as losses, regularizers, constraints, initializers, metrics, activation functions, layers, and even full models, can be customized in very much the same way. Most of the time, you will just need to write a simple function with the appropriate inputs and outputs. Some examples below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "299f49c7-1df0-45ea-9406-d2a2c94d1fd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def my_softplus(z):\n",
    "    ' Return value is just tf.nn.softplus(z)'\n",
    "    return tf.math.log(tf.exp(z) + 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "7dc55477-d87e-492f-a3f7-d822ce683fc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def my_glorot_initializer(shape, dtype=tf.float32):\n",
    "    stddev = tf.sqrt(2. / (shape[0] + shape[1]))\n",
    "    return tf.random.normal(shape, stddev=stddev, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "cda65e96-f15f-4871-b80b-592aed7c9209",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def my_l1_regularizer(weights):\n",
    "    return tf.reduce_sum(tf.abs(0.01 * weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "8e5a2e54-5f26-43f3-9aad-51fcbcdecea4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def my_positive_weights(weights):\n",
    "    ' Return value is just tf.nn.relu(weights)'\n",
    "    return tf.where(weights < 0., tf.zeroes_like(weights), weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ea090e9d-cf51-4c9b-8f16-cb2e5eb83b33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "layer = tf.keras.layers.Dense(\n",
    "    units=30,\n",
    "    activation=my_softplus,\n",
    "    kernel_initializer=my_glorot_initializer,\n",
    "    kernel_regularizer=my_l1_regularizer,\n",
    "    kernel_constraint=my_positive_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be61b1ce-ea67-4565-a84f-0fafe7795ec4",
   "metadata": {},
   "source": [
    "The activiation function will be applied to the output of this Dense layer, and its result will be passed on to the next layer. The layer's weights will be initialized using the value returned by the initializer. At each training step the weights will be passed to the regularization function to compute the regularization loss, which will be added to the main loss to get the final loss used for training. Finally, the constraint function will be called after each training step, and the layer's weights will be replaced by the constained weights.\n",
    "\n",
    "If a function has hyperparameters that need to be saved along with the model, then you will want to subclass the appropriate class. Note that yo umust implement the call() method for losses, layers (including activation functions), and models, or the __ call__() method for regularizers, initializers, and constraints. For metrics, things are a bit different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "1bcb1187-0eaa-4274-b4dd-8ac56edfd18f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyL1Regularizer(tf.keras.regularizers.Regularizer):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        \n",
    "    def __call__(self, weights):\n",
    "        return tf.reduce_sum(tf.abs(self.factor * weights))\n",
    "    \n",
    "    def get_config(self):\n",
    "        return {'factor': self.factor}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a55655-04de-4e5c-a866-7676ced96ca1",
   "metadata": {},
   "source": [
    "## Custom Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ed1de0-e447-4e5e-9a6e-dd1ffeb0a518",
   "metadata": {},
   "source": [
    "Losses and metrics are conceptually not the same thing: losses are used by Gradient Descent to _train_ a model, so they must be differentiable and their gradients should not be 0 everywhere. In contrast, metrics are used to _evaluate_ a model: they must be more easily interpretable, and they can be non-differentiable or have 0 gradients everywhere. \n",
    "\n",
    "That said, in most cases, defining a custom metric function is exactly the same as defining a custom loss function. In fact, we could even use the Huber loss function we created earlier as a metric; it would work just fine. \n",
    "\n",
    "For each batch during training, Keras will compute this metric and keep track of its mean since the beginning of the epoch. Most of the time, this is exactly what you want. But not always! Consider a binary classifier's precision, for example. In this case, what we need is an object that can keep track of the number of true positives and the number of false positives and that can compute their ratio when requested. This is precisely what the tf.keras.metrics.Precision class does. This is called a _streaming metric_ (or _stateful metric_), as iti s gradually updated, batch after batch.\n",
    "\n",
    "If you need to create such a streaming metric, create a subclass of the tf.keras.metrics.Metric class. Here is simple example that keeps track of the total Huber loss and the number of instances seen so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13af4ef0-a74b-4b1a-9185-d9b06f3a4f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_huber(threshold=1.0):\n",
    "    def huber_fn(y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss = threshold * tf.abs(error) - threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "ca2939fc-634d-4513-991f-a7f9e86103f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example using a Loss function as a metric\n",
    "# model.compile(loss='mse', optimizer='nadam', metrics=[create_huber(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "abedd58c-f63e-45b7-a4d0-2fe4cd767749",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class HuberMetric(tf.keras.metrics.Metric):\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        super().__init__(**kwargs) # handles base args (e.g. dtype)\n",
    "        self.huber_fn = create_huber(threshold)\n",
    "        self.total = self.add_weight('total', initializer='zeros')\n",
    "        self.count = self.add_weight('count', initializer='zeros')\n",
    "        \n",
    "    def update_state(self, y_true, y_pred, sample_weights=None):\n",
    "        metric = self.huber_fn(y_true, y_pred)\n",
    "        self.total.assign_add(tf.reduce_sum(metric))\n",
    "        self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
    "        \n",
    "    def result(self):\n",
    "        return self.total / self.count\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, 'threshold': self.threshold}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72689f84-4766-4145-acd4-665ea5063199",
   "metadata": {},
   "source": [
    "Let's walk through the class above:\n",
    "\n",
    "1. The constructor uses the add_weight() method to create the variables needed to keep track of the metric's state over multiple batches - in this case, the sum of all Huber losses (total) and the number of instances seen so far (count). You could just create variables manually if you preferred. Keras tracks any tf.Variable that is set as an attribute (and more generally, any 'trackable' object, such as layers or models).\n",
    "\n",
    "2. The update_state() method is called when you use an instance of this class as a function. It updates the variables, given the labels and predictions for one batch (and sample weights, but in this case we ignore them).\n",
    "\n",
    "3. The result() method computes and returns the final result, in this case the mean Huber metric over all instances. When you use the metric as a function, the update_state() method gets called first, then the result() method is called, and its output is returned.\n",
    "\n",
    "4. We also implement the get_config() method to ensure the threshold gets saved along with the model.\n",
    "\n",
    "5. The default implementation of the reset_states() method resets all variables to 0.0 (but you can override this if needed).\n",
    "\n",
    "Keras will take care of variable persistence seamlessly; no action is required. Now that we have built a streaming metric, building a custom layer will seem like a walk in the park!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0508ca75-0bc4-4112-95f6-f9db59350845",
   "metadata": {},
   "source": [
    "## Custom Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251f0275-0541-4ba8-be1e-958432191dbe",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea5c87f5-9c9c-4509-bdd9-47fdc86618a0",
   "metadata": {},
   "source": [
    "## Custom Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b218b7-4b57-4699-b775-009ac92e83d8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0856d2bd-ae47-4be9-bb04-1d027896e28a",
   "metadata": {},
   "source": [
    "# Losses and Metrics Based on Model Internals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8622767-94ca-42f2-956e-aa393002ef09",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f47eef3-2afa-4662-b717-bdc75706890f",
   "metadata": {},
   "source": [
    "## Computing Gradients Using Autodiff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f7d7f5-de82-42ba-907c-8eb8ffd0dc20",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4afb229b-0e37-473e-b59d-2312f26c6ba8",
   "metadata": {},
   "source": [
    "## Custom Training Loops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe02832-4608-42fb-89f4-9073d9fc793b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb709f7b-93d4-478f-8fae-18bdd8c3d8df",
   "metadata": {},
   "source": [
    "# TensorFlow Functions and Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c327b537-9b2d-4d31-b605-7f144c2609f8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a169d43a-aa8b-4ecd-98eb-d597b3cd26fe",
   "metadata": {},
   "source": [
    "## AutoGraph and Tracing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880d18d2-6ee4-4a14-9173-c2e619ad822f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ff2b696-5007-46d7-b3fb-1bc3e1e7592b",
   "metadata": {},
   "source": [
    "## TF Function Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67a147c-751f-40a3-92cd-73fb0ab9da20",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf4a771b-1fc6-4c88-940a-c0d674a548df",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841e5d5b-aa28-450a-9d18-655582896691",
   "metadata": {},
   "source": [
    "1. **How would you describe TensorFlow in a short sentence? What are its main features? Can you name other popular Deep Learning libraries?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e49138-9667-45c5-8371-f82056a81e03",
   "metadata": {},
   "source": [
    "My Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d491fb93-8e27-46c0-b03d-d5a3238eb808",
   "metadata": {},
   "source": [
    "Book Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34490673-fefa-419f-b854-3315263e5e1a",
   "metadata": {},
   "source": [
    "2. **Is TensorFlow a drop-in replacement for NumPy? What are the main differences between the two?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4ce4d8-9f5d-481c-bc29-6cefb28cc9ed",
   "metadata": {},
   "source": [
    "My Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a22016a-6d7d-4915-a7ae-2ca934c002da",
   "metadata": {},
   "source": [
    "Book Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6a86c9-8004-4fd7-a0a1-80167b38d1ad",
   "metadata": {},
   "source": [
    "3. **Do you get the same result with tf.range(10) and tf.constant(np.arange(10))?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78906a64-c3e5-418d-b01b-257fd44ab716",
   "metadata": {},
   "source": [
    "My Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215f8113-ac06-4297-bdac-ea2ee947d1e7",
   "metadata": {},
   "source": [
    "Book Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aae2392-877c-4354-982c-1b8323e18abb",
   "metadata": {},
   "source": [
    "4. **Can you name six other data structures available in TensorFlow, beyond regular tensors?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cea924e-71ae-4706-93ab-ed0fa790c54c",
   "metadata": {},
   "source": [
    "My Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7fa164-9c98-486c-aa67-e6f40e4a8fa6",
   "metadata": {},
   "source": [
    "Book Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c29b2f-d248-4b2e-9a99-24f19ef63f41",
   "metadata": {},
   "source": [
    "5. **A custom loss function can b e defined by writing a function or by subclassing the keras.losses.Loss class. When would you use each option?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2566cb-d6d8-41a0-8e32-d6b19fc47ed0",
   "metadata": {},
   "source": [
    "My Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75472267-358a-488d-be68-b53444ce5ca8",
   "metadata": {},
   "source": [
    "Book Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c859aa-2c5b-47ce-bf19-7d7aca9534c9",
   "metadata": {},
   "source": [
    "6. **Similarly, a custom metric can be defined in a function or a subclass of keras.metrics.Metric. When would you use each option?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326a754c-62f6-4267-8d10-61cab0b82ada",
   "metadata": {},
   "source": [
    "My Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b942dfa-05c4-418f-9585-2faf1bc2e4e1",
   "metadata": {},
   "source": [
    "Book Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc1057b-ee1f-47df-a11e-6f3f7b320188",
   "metadata": {},
   "source": [
    "7. **When should you create a custom layer versus a custom model?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06639a46-48c7-466d-990d-7b8537bcf9ba",
   "metadata": {},
   "source": [
    "My Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01d7645-079e-4827-8018-02df2ca52a03",
   "metadata": {},
   "source": [
    "Book Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a2d882-df35-4922-b521-7d9bd523dc72",
   "metadata": {},
   "source": [
    "8. **What are some use cases that require writing your own custom training loop?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15426460-ea3b-4d2d-b9f0-18209ba5d91c",
   "metadata": {},
   "source": [
    "My Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffda58c-a65b-4a45-83eb-82a6b04a8bd2",
   "metadata": {},
   "source": [
    "Book Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822c5080-e975-46fc-ae53-82bfe89b349c",
   "metadata": {},
   "source": [
    "9. **Can custom Keras components contain arbitrary Python code, or must they be convertible to TF Functions?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55c444c-39de-47ae-92f0-6a0b5c635c53",
   "metadata": {},
   "source": [
    "My Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebacc5dc-bb56-4e96-a3a5-1ec27d67cc80",
   "metadata": {},
   "source": [
    "Book Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09841192-a3cf-44af-ad5a-738c4f4bf49c",
   "metadata": {},
   "source": [
    "10. **What are the main rules to respect if you want a function to be convertible to a TF Function?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eaf456c-2590-4137-afe8-36da885b7715",
   "metadata": {},
   "source": [
    "My Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3511c4c-76b6-4191-9873-23867f3c21ec",
   "metadata": {},
   "source": [
    "Book Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b93346-38f7-4e70-aafb-bb9acd75a85b",
   "metadata": {},
   "source": [
    "11. **When would you need to create a dynamic Keras model? How do you do that? Why not make all your models dynamic?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1f1ab2-bc17-48f5-99c5-4a72dcd2d87b",
   "metadata": {},
   "source": [
    "My Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354ca20f-efd6-4966-9a08-c296cc2d3fc8",
   "metadata": {},
   "source": [
    "Book Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1358e9-3307-4eeb-9776-18ed91f282f4",
   "metadata": {},
   "source": [
    "12. **Implement a custom layer that performs *Layer Normalization* (we will use this type of layer in Chapter 15):**\n",
    "\n",
    "    1. The build() method should define two trainable weights $\\alpha$ and $\\beta$, both of shape input_shape[-1:] and data type tf.float32. $\\alpha$ should be initialized with 1s and $\\beta$ with 0s\n",
    "\n",
    "    2. The call() method should compute the mean $\\mu$ and standard deviation $\\sigma$ of each instance's features. For this, you can use tf.nn.moments(inputs, axes=-1, keepdims=True), which returns the mean $\\mu$ and the variance $\\sigma^{2}$ of all instances (compute the square root of the variance to get the standard deviation). Then the function should computer and return $\\alpha\\bigotimes\\frac{(X - \\mu)}{\\sigma + \\epsilon} + \\beta$, where \\bigotimes represents itemwise multiplication and \\epsilon is a smoothing term (small constant to avoid division by zero, e.g. 0.001)\n",
    "\n",
    "    3. Ensure that your custom layer produces the same (or very nearly the same) outoput as the keras.layers.LayerNormalization layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bfc97f-7098-4d61-9a4c-336c1daea037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e483fef-5995-4d26-a6b8-838cd0a28f9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56670af3-7a9f-4648-8843-1e92759d2a41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bc7a4f-fb56-4a6e-95e1-7daf08210c99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde4ce7f-ac02-45de-bd5a-eec3b61e5027",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19575386-b124-4952-a369-9f96ebc494f9",
   "metadata": {},
   "source": [
    "13. **Train a model using a custom training loop to tackle the Fashion MNIST dataset (see Chapter 10).**\n",
    "\n",
    "    1. Display the epoch, iteration, mean training loss, and mean accuracy over each epoch (updated at each iteration), as well as the validation loss and accuracy at the end of each epoch.\n",
    "    \n",
    "    2. Try using a different optimizer with a different learning rate for the upper layers and the lower layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419fb924-5af8-4ab6-a862-b7d79a746011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb16dd8-3429-49be-9f1e-8a3e1b664fb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d5aa42-5cc7-4f39-8ce0-8a50ffcdb32c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4ad9d4-6844-4977-9f9d-dc7b89b9e5de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831d5fdf-bc7f-4313-9aff-658a17d4b2f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b18f22-d5d3-451b-ae46-0b5c30002f1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
