{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f856f5cc-8061-40e9-a47b-cf62711ea2d6",
   "metadata": {},
   "source": [
    "# Ensemble Learning and Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f31c0b-71f2-4f92-a375-17db04c9b7b2",
   "metadata": {},
   "source": [
    "If you aggregate the predictinos of a group of predictors (such as classifers or regressors), you will often get better predictions than with the best individual predictor. A group of predictors is called an <i> ensemble;</i> thus, this technique is called <i>Ensemble Learning,</i> and an Ensemble Learning algorithm is called an <i>Ensemble method</i>.\n",
    "\n",
    "A <i>Random Forest</i> is one of the most powerful Machine Learning algorithms available today and by design it is an esemble of Decision Trees.  \n",
    "\n",
    "You will often use Ensemble methods near the end of a project, once you have already built a few good predictors, to combine them into an even better predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff0e5d6-443f-4625-93c1-06be3b0b9f00",
   "metadata": {},
   "source": [
    "### Voting Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124109fc-3b45-4c3a-ac3a-dc6b9a7b480f",
   "metadata": {},
   "source": [
    "Suppose you have trained a few classifiers, each one achieving about 80% accuracy. A very simple way to create an even better classifier is to aggregate the predictions of each classifier and predict the class that gets the most votes.  This majority-vote classifier is called <i> hard voting </i>. \n",
    "\n",
    "Somewhat suprisingly, this voting classifier often achieves a higher accuracy than the best classifier in the ensemble.  In fact, even if each classifier is a <i> weak learner </i> (meaning it does only slightly better than random guessing), the ensemble can still be a <i> strong learner </i> (achieving high accuracy), provided there are a sufficient number of weak learners and they are sufficiently diverse.\n",
    "\n",
    "Suppose you build an ensemble containing 1,000 classifiers that are individually correct only 51% of the time (barely better than random guessing).  If you predict the majority voted class, you can hope for up to 75% accuracy!  However, this is only true if all classifiers are perfectly independent, making uncorrelated errors, which is clearly not the case because they are trained on the same data.\n",
    "\n",
    "Ensemble methods work best when the predictors are as independent from one another as possible.  One way to get diverse classifiers is to train them using very different algorithms.  This increases the chance that they will make very different types of errors, improving the ensemble's accuracy.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c748d1bb-3c0c-4e65-8659-6cc3a9499518",
   "metadata": {},
   "source": [
    "#### Example 1: Training a voting classifier in Scikit-Learn composed of 3 diverse classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b9f156e-6c1b-4a2c-a39b-f5d0f0b69633",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.8739393939393939\n",
      "RandomForestClassifier 0.9896969696969697\n",
      "SVC 0.990909090909091\n",
      "VotingClassifier 0.9896969696969697\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris, make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# iris_ = load_iris()\n",
    "# X = iris_.data[:, 3:]\n",
    "# y = iris_.target\n",
    "\n",
    "X, y = make_moons(n_samples=10000, noise=0.15)\n",
    "\n",
    "log_clf_ = LogisticRegression()\n",
    "rnd_clf_ = RandomForestClassifier()\n",
    "svm_clf_ = SVC()\n",
    "\n",
    "voting_clf_ = VotingClassifier(\n",
    "    estimators=[('lr', log_clf_), ('rf', rnd_clf_), ('svc', svm_clf_)],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "voting_clf_.fit(X_train, y_train)\n",
    "for clf in (log_clf_, rnd_clf_, svm_clf_, voting_clf_):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred_ = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24b8fec-a348-48d7-ab65-d89448ef5f35",
   "metadata": {},
   "source": [
    "If all classifiers are able to estimate class probabilities (ie they have a predict_proba() method), then you can tell Scikit-Learn to predict the class with the highest class probability, averaged over all the individual classifiers.  This is called <i>soft voting</i>.  It often achieves higher performance than hard voting because it gives more weight to highly confident votes.  All you need to do is replace voting='hard' with voting='soft' and ensure that all classifiers can estimate class probabilities.  This is not the case for the SVC class by default, so you need to set its probability hyperparamter to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af4920a1-1dd3-4928-a3cf-9273b9a9392f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.8718181818181818\n",
      "RandomForestClassifier 0.99\n",
      "SVC 0.9921212121212121\n",
      "VotingClassifier 0.9903030303030304\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris, make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# iris_ = load_iris()\n",
    "# X = iris_.data[:, 3:]\n",
    "# y = iris_.target\n",
    "\n",
    "X, y = make_moons(n_samples=10000, noise=0.15)\n",
    "\n",
    "log_clf_ = LogisticRegression()\n",
    "rnd_clf_ = RandomForestClassifier()\n",
    "svm_clf_ = SVC(probability=True)\n",
    "\n",
    "voting_clf_ = VotingClassifier(\n",
    "    estimators=[('lr', log_clf_), ('rf', rnd_clf_), ('svc', svm_clf_)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "voting_clf_.fit(X_train, y_train)\n",
    "for clf in (log_clf_, rnd_clf_, svm_clf_, voting_clf_):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred_ = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a69337-18ab-4916-bffa-153779e5f722",
   "metadata": {},
   "source": [
    "### Bagging and Pasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b1579d-87bb-4226-b134-ca6b213b03f9",
   "metadata": {},
   "source": [
    "Another approach is to use the same training algorithm for every predictor and train them on different random subsets of the training set.  When sampling is performed <i> with </i> replacement, this method is called <i> bagging </i>.  When sampling is performed <i> without </i> replacement, it is called <i> pasting </i>.  Most on this here: https://homl.info/21\n",
    "\n",
    "<b> In other words, both bagging and pasting allow training instances to be sampled several times across multiple predictors, but only bagging allows training instances to be sampled several times for the same predictor </b>\n",
    "\n",
    "<u> Bagging and pasting involves training several predictors on different random samples of the training set </u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e0adb5-f0a9-4aaa-8169-c21e871700dc",
   "metadata": {},
   "source": [
    "Once all predictors are trained the aggregation function is typically the statistical mode (the most frequent prediction) for classification, or the average for regression.  In general, aggregation of predictions reduces both bias and variance.  The net result is that the ensemble has a simlair bias but lower variance than a single predictor trained on the original training set. \n",
    "\n",
    "<b> Bagging and Pasting scale very well </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedd8aed-62bc-47aa-9737-cba30fe7d983",
   "metadata": {},
   "source": [
    "#### Example 2: Bagging and Pasting in Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b34d1ade-4a11-467f-9179-6bbaf19f5f07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bag_clf_ = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators=500, max_samples=100, bootstrap=True, n_jobs=-1\n",
    ")\n",
    "bag_clf_.fit(X_train, y_train)\n",
    "y_pred = bag_clf_.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac85935b-a87c-4bb5-b8a2-14e1da932909",
   "metadata": {},
   "source": [
    "The BaggingClassifier automatically performs soft voting instead of hard voting if the base classifier can estimate class probabilities.\n",
    "\n",
    "Bootstrapping introduces a bit more diversity in the subsets that each predictor is trained on, so bagging ends up with a slightly higher bias than pasting; but the extra diversity also means that the predictors end up being less correlated, so the ensemble's variance is reduced.  Overall, bagging often results in better models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb6e29a-b653-49f0-be66-0d6171c853a1",
   "metadata": {},
   "source": [
    "### Out-of-Bag Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032c69a4-4629-4000-869e-da6d9a9d79fa",
   "metadata": {},
   "source": [
    "By default a BaggingClassifier samples <i> m </i> training instances with replacement (bootstrap=True), where <i> m </i> is the size of the training set.  This means that only about 63% of the training instances are sampled on average for each predictor $1 - \\exp(-1) = 0.63212$.  The remaining 37% of the training instances that are not sampled are called <i> out of bag (oob) </i> instances.  \n",
    "\n",
    "Since a predictor never sees the oob instances during training, it can be evaluated on these instances, without the need for a separate validation set.  \n",
    "\n",
    "In Scikit-Learn you can set oob_score=True when creating a BaggingClassifier to request an automatic oob evaluation after training.  \n",
    "\n",
    "The oob decision function is available for each training instance trhough the oob_decision_function_ variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfe583d-7f77-4c5b-8888-3858cee171cf",
   "metadata": {},
   "source": [
    "#### Example 3: Bagging with Out-of-Bag Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "143dd4dd-cb8b-463d-9fc1-3435ab05bb6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB Score: 0.9877611940298507, Accuracy: 0.9896969696969697\n"
     ]
    }
   ],
   "source": [
    "bag_clf_ = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators=500, bootstrap=True, n_jobs=-1, oob_score=True\n",
    ")\n",
    "\n",
    "bag_clf_.fit(X_train, y_train)\n",
    "y_pred_ = bag_clf_.predict(X_test)\n",
    "accuracy_score_ = accuracy_score(y_test, y_pred_)\n",
    "print(f'OOB Score: {bag_clf_.oob_score_}, Accuracy: {accuracy_score_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f9bd0b-e507-4bb0-bc9b-afaba45dd1f3",
   "metadata": {},
   "source": [
    "### Random Patches and Random Subspaces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd67ea5-6593-465b-94b0-dc02c3162867",
   "metadata": {},
   "source": [
    "The BaggingClassifier class supports sampling the features as well.  Sampling is controlled by two hyperparameters: <b>max_features</b> and <b>bootstrap_features</b>.  They work the same way as <b>max_samples</b> and <b>bootstrap</b>, but for feature sampling instead of instance sampling.  Thus, each predictor will be trained on a random subset of the input features.\n",
    "\n",
    "<b> This technique is particularly useful when you are dealing with high-dimensional inputs (such as inputs). </b>\n",
    "\n",
    "Sampling both trianing instances and features is called the <i> Random Patches </i> method.  Keeping all training instances (by setting bootstrap=False and max_samples=1.0) but sampling features (by setting bootstrap_features=True and/or max_features to a value smaller than 1.0) is called <i>Random Subspaces</i> method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47d5991-989d-4581-a3a6-e52f71bfe671",
   "metadata": {},
   "source": [
    "### Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b50f34-774f-4c60-bb6f-cf4d4d25a688",
   "metadata": {},
   "source": [
    "#### Example 4: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a265de1-30f3-4d24-abd8-3926d50645c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'With few exceptions, a RandomForestClassifier has all the hyperparameters of a DecisionTreeClassifier plus all the hyperparameters of a BaggingClassifer to control the ensemble itself.'\n",
    "\n",
    "# The following code uses all available CPU cores to train a RAndom Forest classifier with 500 trees, each tree limited to a maximum of 16 nodes.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd_clf_ = RandomForestClassifier(\n",
    "    n_estimators=500,\n",
    "    max_leaf_nodes=16,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rnd_clf_.fit(X_train, y_train)\n",
    "y_pred_rf_ = rnd_clf_.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91936df7-af65-4577-86cd-fc18d3e838bb",
   "metadata": {},
   "source": [
    "### Extra-Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853e0252-7540-495b-84a6-74d740e2de45",
   "metadata": {},
   "source": [
    "When you are a growing a tree in a Random Forest, at each node only a random subset of the features is considered for splitting.  It is possible to make trees even more random by also using random thresholds for each feature rather than searching for the best possible thresholds.  A forest of such extremely random trees is called an <i> Extremely Randomized Trees Ensemble </i>.\n",
    "\n",
    "Once again, this technique trades more bias for a lower variance (Recall that low bias and high variance is characteristic of underfitting. And high bias and low variance is characteristic of overfitting).  It also makes Extra-Tres much faster to train than regular Random Forests, because finding the best possible threshold for each feature at every node is one of the most time-consuming tasks of growing a tree.\n",
    "\n",
    "<b>You can create an Extra-Trees classifier using Scikit-Learn's ExtraTreesClassifier class. Its API is identical to the RandomForestClassifier class </b>.\n",
    "\n",
    "It is hard to tell in advance whether a RandomForestClassifier will perform better or worse than an ExtraTreesClassifier.  Generally, the only way to know is to try both and compare them using cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de0b019-2e7a-47d5-b66a-7ad011778b44",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a35426-9b89-4d6a-9223-d88a98e70212",
   "metadata": {},
   "source": [
    "Yet another great quality of Random Forests is that they make it easy to measure the relative importance of each feature.  Scikit-Learn measures a feature's importance by looking at how much the tree nodes that use that feature reduce impurity on average.  More precisely, it is a weighted average, where each node's weight is equal to the number of training samples that are associated with it. \n",
    "\n",
    "<b> You can access the result using the <i> feature_importances_ </i> variable </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e756f1d1-2c31-42df-8804-b6e33f434957",
   "metadata": {},
   "source": [
    "#### Example 5: Access Random Forest Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f45fe82-a7d2-4996-af9f-cb660f960b22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length (cm) 0.09711331661572171\n",
      "sepal width (cm) 0.024867402780438135\n",
      "petal length (cm) 0.4403408557941626\n",
      "petal width (cm) 0.43767842480967756\n"
     ]
    }
   ],
   "source": [
    "iris_ = load_iris()\n",
    "rnd_clf_ = RandomForestClassifier(\n",
    "    n_estimators=500,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rnd_clf_.fit(iris_['data'], iris_['target'])\n",
    "for name, score in zip(iris_['feature_names'], rnd_clf_.feature_importances_):\n",
    "    print(name, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78694757-54cd-4a2e-a693-4dcf964bc735",
   "metadata": {},
   "source": [
    "### Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f291ae-1e11-4c2a-a6c8-e1a4180e53eb",
   "metadata": {},
   "source": [
    "<i> Boosting </i> refers to any Ensemble method that can combine several weak learners into a strong learner. The general idea of most boosting methods is to train predictors sequentially, each trying to correct its predecessor.  <b> There are many boosting methods available, but by far the most popular are <i> AdaBoost </i> (short for Adaptive Boosting) and <i> Gradient Boosting </i>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0821e5-caeb-4ee9-881d-ab543ea7ed35",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5f8795-8cd8-4437-aafa-3e0e82e48333",
   "metadata": {},
   "source": [
    "One way for a new predictor to correct its predecessor is to pay a bit more attention to the training instances that the predecessor underfitted.  This is the technique used by AdaBoost.\n",
    "\n",
    "For example, when training an AdaBoost classifer, the algorithm first trains a base classifier (such as a Decision Tree) and uses it to make predictions on the training set.  The algorithm then increases the relative weight of misclassified training instances.  Then it trains a second classifier, using the updated weights, and again makes predictions on the training set, updates the instance weights, and so on.\n",
    "\n",
    "This sequential learning technique has some similarities with Gradient Descent, except that instead of tweaking a single predictor's parameters to minimize a cost function, AdaBoost adds predictors to the ensemble, gradually making it better.\n",
    "\n",
    "Once all predictors are trained, the ensemble makes predictions very much like bagging or pasting, except that predictors have different weights depending on their overall accuracy on the weighted training set.\n",
    "\n",
    "<b> There is one important drawback to this sequential learning technique: it cannot be parallelized, since each predictor can only be trained after the previous predictor has been trained and evaluated </b>\n",
    "\n",
    "To make predictions, AdaBoost simply computes the predictions of the all the predictors and weighs them using the predictor weights $\\alpha_j$.  The predicted class is the one that receives the majority of weighted votes.\n",
    "\n",
    "<b>Scikit-Learn uses a multiclass version of AdaBoost called SAMME (Stagewise Additive Modeling using a Multiclaass Exponential loss function).  If the predictors can estimate class probabilities (predict_proba()), Scikit-Learn can use a variant of SAAME called SAMME.R which relies on class probabilities rather than predictions and generally performs better.</b>\n",
    "\n",
    "A Decision Stump is a Decision Tree with max_depth=1 and is the default base estimator for the AdaBoostClassifier class.  If your AdaBoost ensemble is overfitting the training set, you can try reducing the number of estimators or more strongly regularizing the base estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878880c6-2de7-49b0-b4dc-060bf85598cf",
   "metadata": {},
   "source": [
    "#### Example 6: AdaBoostClassifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6595580-159a-42f0-8873-7067a16442a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.993030303030303\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf_ = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1),\n",
    "    n_estimators=200,\n",
    "    algorithm='SAMME.R',\n",
    "    learning_rate=0.5\n",
    ")\n",
    "ada_clf_.fit(X_train, y_train)\n",
    "y_pred_ = ada_clf_.predict(X_test)\n",
    "accuracy_score_ = accuracy_score(y_test, y_pred_)\n",
    "print(f'Accuracy: {accuracy_score_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc18ef76-e5e5-47d3-b6ad-a2dd2ba5d1bd",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021040c1-72ec-4633-be72-8493d5dd6264",
   "metadata": {},
   "source": [
    "Another very popular boosting algorithm is <i>Gradient Boosting</i>.  Just like AdaBoost, Gradient Boosting works by sequentially adding predictors to an ensemble, each one correcting its predecessor.  However, instead of tweaking the instance weights at every iteration like AdaBoost does, this method tries to fit the new predictor to the <i>residual errors</i> made by the previous predictor.\n",
    "\n",
    "The learning_rate hyperparameter scales the contribution of each tree.  If you set it to a low value, such as 0.1, you will need more trees in the ensemble to fit the training set, but the predictions will usually generalize better.  This is a regularization technique called <i> shrinkage </i>.\n",
    "\n",
    "In order to find the optimal number of trees, you can use early stopping.  A simple way to implement this is to use the staged_predict() method; it returns an iterator over the predictions made by the ensemble at each stage of the training.  It is also possible to implement early stopping by actually stopping training early.  You can do so by setting warm_start=True, which makes Scikit-Learn keep existing trees when the fit() method is called, allowing incremental training.\n",
    "\n",
    "The GradientBoostingRegressor class also suppports a subsample hyperparameter, which specifies the fraction of training instances to be used for training each tree. As you can probably guess by now, this technique trades a higher bias for a lower variance.  It also speeds up training considerably.  This is called <i> Stochastic Gradient Boosting </i>.\n",
    "\n",
    "It is possible to use Gradient Boosting with other cost functions.  This is controlled by the loss hyperparameter.\n",
    "\n",
    "It is worth noting that an optimized implementation of Gradient Boosting is available in the popular Python library XGBoost (Extreme Gradient Boosting).  XGBoost is often an important component of the winning entries in ML competitions.  XGBoost also offers several nice features, such as automatically taking care of early stopping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3286a0d2-42b0-4563-b5d8-e7468c4fd503",
   "metadata": {},
   "source": [
    "#### Example 7: Manual Gradient Boostings and GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cb45509-f79b-46ae-9f00-6666b9a58b3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.4235663441968759\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "X, y = load_diabetes(as_frame=True, scaled=True).get('data').loc[:, ['age', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']], load_diabetes(as_frame=True, scaled=True).get('target')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42)\n",
    "\n",
    "tree_reg1_ = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg1_.fit(X_train, y_train)\n",
    "\n",
    "y2 = y_train - tree_reg1_.predict(X_train)\n",
    "tree_reg2_ = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg2_.fit(X_train, y2)\n",
    "\n",
    "y3 = y2 - tree_reg2_.predict(X_train)\n",
    "tree_reg3_ = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg3_.fit(X_train, y3)\n",
    "\n",
    "y_pred_ = sum(tree.predict(X_test).round() for tree in (tree_reg1_, tree_reg2_, tree_reg3_))\n",
    "r2_ = r2_score(y_test, y_pred_)\n",
    "print(f'R2: {r2_}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eea47a8f-46ca-4d21-8964-41df454f236b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.536799085946732\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbrt_ = GradientBoostingRegressor(max_depth=2, n_estimators=3, learning_rate=0.7)\n",
    "gbrt_.fit(X_train, y_train)\n",
    "y_pred_ = gbrt_.predict(X_test)\n",
    "r2_ = r2_score(y_test, y_pred_)\n",
    "print(f'R2: {r2_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e892010e-f391-4c5b-b4ed-015947aaa76d",
   "metadata": {},
   "source": [
    "#### Example 8: Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de842e30-bb03-45e6-8932-b85370f871e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.5495590801562829\n"
     ]
    }
   ],
   "source": [
    "' Implementing staged_predict()'\n",
    "import numpy as np\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, random_state=42)\n",
    "\n",
    "gbrt_ = GradientBoostingRegressor(max_depth=2, n_estimators=120)\n",
    "gbrt_.fit(X_train, y_train)\n",
    "\n",
    "errors = [\n",
    "    mean_squared_error(y_val, y_pred) for y_pred in gbrt_.staged_predict(X_val)\n",
    "]\n",
    "bst_n_estimators_ = np.argmin(errors) + 1\n",
    "\n",
    "gbrt_best_ = GradientBoostingRegressor(max_depth=2, n_estimators=bst_n_estimators_)\n",
    "gbrt_best_.fit(X_train, y_train)\n",
    "y_pred_ = gbrt_best_.predict(X_test)\n",
    "r2_ = r2_score(y_test, y_pred_)\n",
    "print(f'R2: {r2_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c624333b-9cf5-42fb-b0c6-89605b092bfb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.5562674641315657\n"
     ]
    }
   ],
   "source": [
    "' Implementing warm_start=True'\n",
    "\n",
    "gbrt_ = GradientBoostingRegressor(max_depth=2, warm_start=True)\n",
    "min_val_error_ = float('inf')\n",
    "error_going_up_ = 0\n",
    "for n_estimators in range(1, 120):\n",
    "    gbrt_.n_estimators = n_estimators\n",
    "    gbrt_.fit(X_train, y_train)\n",
    "    y_pred_ = gbrt_.predict(X_val)\n",
    "    val_error_ = mean_squared_error(y_val, y_pred_)\n",
    "    if val_error_ < min_val_error_:\n",
    "        min_val_error_ = val_error_\n",
    "        error_going_up_ = 0\n",
    "    else:\n",
    "        error_going_up_ += 1\n",
    "        if error_going_up_ == 5:\n",
    "            break # Early stopping mechanism\n",
    "\n",
    "y_pred_ = gbrt_.predict(X_test)\n",
    "r2_ = r2_score(y_test, y_pred_)\n",
    "print(f'R2: {r2_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ced5e3b-84fd-4169-80e5-533a8a46e3ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae62ef4c-a1d7-4bbe-9a5b-c798d796294c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:66.19632\n",
      "[1]\tvalidation_0-rmse:59.65037\n",
      "[2]\tvalidation_0-rmse:55.09643\n",
      "[3]\tvalidation_0-rmse:55.44572\n",
      "[4]\tvalidation_0-rmse:54.75318\n",
      "[5]\tvalidation_0-rmse:54.72742\n",
      "[6]\tvalidation_0-rmse:55.46946\n",
      "[7]\tvalidation_0-rmse:55.31054\n",
      "[8]\tvalidation_0-rmse:55.98979\n",
      "[9]\tvalidation_0-rmse:56.59273\n",
      "[10]\tvalidation_0-rmse:56.73968\n",
      "R2: 0.5562674641315657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Steph\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "' Using XGBoost'\n",
    "import xgboost\n",
    "\n",
    "xgb_reg_ = xgboost.XGBRegressor()\n",
    "xgb_reg_.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=5)\n",
    "y_pred = xgb_reg_.predict(X_val)\n",
    "r2_ = r2_score(y_test, y_pred_)\n",
    "print(f'R2: {r2_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe66ca5-ec80-4125-9782-8eaa71a7509c",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c970b63-97af-4219-8c9f-7023e9abf2a3",
   "metadata": {},
   "source": [
    "The last Ensemble method we will discuss in this chapter is called <i> stacking </i> (short for stacked generalization).  It is based on a simple idea: instead of using trivial functions (such as hard voting) to aggregate the predictions of all predictors in an ensemble, why don't we train a model to perform this aggregation?\n",
    "\n",
    "Ex. Three predictors predcit values (3.1, 2.7, and 2.9) and the final predictor (called a <i> blender </i> or a <i> meta learner </i>) takes the predictions as inputs and makes the final prediction.  \n",
    "\n",
    "To train a blender, a common approach is to use a hold-out set.  Alternatively, it is possible to use out-of-fold predictions.  In some contexts this is called stacking, while using a hold-out set is called blending.  For many people these terms are synonymous.\n",
    "\n",
    "It is actually possible to train several blenders (e.g. one using Linear Regression, another using Random Forest, etc.) to get a whole layer of blenders.  The trick is to split the training set into three subsets: the first one is used to train the first layer, the second one is used to create the training set used to train the second layer (using predictions made by the predictors of the first layer), and the third one is used to create the training set to train the third layer (using predictions made by the predictors of the second layer.)  Once this is done, we can make a prediction for a new instance by going through each layer sequentially.\n",
    "\n",
    "Unfortunately, Scikit-Learn does not support stacking directly, but it is not too hard to roll out your own implementation (see the following exercises.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7731f6-5aad-478c-bad5-9ebfd6bd0a1e",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e725392-cd5c-4157-9c78-d090ff257745",
   "metadata": {},
   "source": [
    "<b> 1. If you have trained five different models on the exact same training data, and they all achieve a 95% precision, is there any chance that you can combine these models to get better results?  If so, how? If not, why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b7dffd-1ab7-4fe8-b289-f113265980ec",
   "metadata": {},
   "source": [
    "My answer:\n",
    "\n",
    "Ensemble models work best when the invidiual models have uncorrelated errors.  In other words, if they've been trained on different data or trained in different ways.  In this case, we don't know what the five different models are.  If they are all different models then yes, there is a good chance that combining them into an ensemble and utilizing hard or soft voting will yield getter results than any one model.  However, if they are all the same model, for example SVMs, trained on the exact same data then no it is unlikely that combining them will yield better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f8a3fd-f198-438a-947b-43a749ab092f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f255cd8-a5e0-4504-940a-91a8e1be7a45",
   "metadata": {},
   "source": [
    "<b> 2. What is the difference between hard and soft voting classifiers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2dad8f-d364-4d64-9619-18a206dc4416",
   "metadata": {},
   "source": [
    "My answer:\n",
    "\n",
    "Hard voting is essentially taking the mode prediction from all of the individual models.  Soft voting occurs when each of the models in the ensemble can supply the probability of their prediction (predict_proba() for scikit-learn models).  In which case the ensemble prediction will be the probability-weighted prediction of the all of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e848d78-9fe2-45f6-ab54-432fa013e880",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a3b8c97-f0f3-4345-a03f-a1ae16c8b832",
   "metadata": {},
   "source": [
    "<b> 3. Is it possible to speed up training of a bagging ensemble by distributing it across multiple servers?  What about pasting ensembles, boosting ensembles, Random Forests, or stacking ensembles?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c257064d-5894-4225-9605-fba812078c13",
   "metadata": {},
   "source": [
    "My answer:\n",
    "\n",
    "1. <b>Baggging</b>: Since bagging just randomizes the training set then pulls a sample from that randomization for each model to train on you can run it in parallel for effeciency gains.\n",
    "1. <b>Pasting</b>: Since pasting divvys up the original training set and trains models on each subset you can run it in parallel for effeciency gains.\n",
    "1. <b>Boosting</b>: Since boosting requires the outputs from the predecessor model as inputs to determine new weights it cannot be run in parallel.  \n",
    "1. <b>Random Forests</b>: There's no reason you can't run various ML models in parallel.\n",
    "1. <b>Stacking</b>: Since stacking relies on the predictions of trained models it an only be parallelized if those models are finished training.  Training the blender(s) on the dataset of predictions can be run in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f191e6c-a4d9-46a8-a2c1-31185be63510",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5a10f0a-687c-4759-a70f-979110491af5",
   "metadata": {},
   "source": [
    "<b> 4. What is the benefit of out-of-bag evaluation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8e9584-b2a3-4745-8e37-9c5811143807",
   "metadata": {},
   "source": [
    "My answer:\n",
    "\n",
    "Since a predictor never sees the oob instances during training, it can be evaluated on these instances, without the need for a separate validation set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86579e7-6ec2-48ef-828f-3db148dacfd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ec3afe6-b7be-4e97-81d5-3bc34e44830a",
   "metadata": {},
   "source": [
    "<b> 5. What makes Extra-Trees more random than regular Random Forests?  How can this extra randomness help?  Are Extra-Trees slower or faster than regular Random Forests?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4298a7f-f7de-45c5-aec0-cbd40f2054c3",
   "metadata": {},
   "source": [
    "My answer:\n",
    "\n",
    "At each node of a Random Forest a random subset of features is selected and the optimal boundary is found for those features.  When utilizing Extra-Trees that boundary condition is randomized. You can technically create several Random Forests using Extra-Trees on the same dataset and get several models that have loosely correlated error thus increasing the predictive power of an ensemble of these models. Extra-Trees trades reduced variance for more bias and speeds up the training.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554500dd-0834-4212-a455-139e2f527183",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d0ec801-aa60-46de-a6c3-3abd596c166d",
   "metadata": {},
   "source": [
    "<b> 6. If your AdaBoost ensemble underfits the training data, which hyperparameters should you tweak and how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11667f3b-2b1f-4869-891e-de70ab490397",
   "metadata": {},
   "source": [
    "My Answer:\n",
    "\n",
    "Start by trying to increase n_estimators then if the model is still underfitting reduce other regularization hyperparameters on the base estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb25db2-7047-4f79-bc3c-b954553d0a3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5f08897-8bdc-4b7a-a100-15b9bcfedc5e",
   "metadata": {},
   "source": [
    "<b> 7. If your Gradient Boosting ensemble overfits the training set, should you increase or decrease the learning rate?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e659851-1c55-4131-ae2b-b515a46ef08e",
   "metadata": {},
   "source": [
    "My Answer:\n",
    "\n",
    "Decrease the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f03317e-d918-43ce-b554-3ab4c7a1d97a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6cc436eb-7649-48b0-befa-9e24cba636ee",
   "metadata": {},
   "source": [
    "<b> 8. Load the MNIST data and split it into a training set, a validation set, and a test set (50,000, 10,000, 10,000 samples).  Then train various classifiers, such as a Random Forest classifier, an Extra-Trees classifier, and an SVM classifier.  Next, try to combine them into an ensemble that outperforms each individual classifier on the validation set, using soft or hard voting.  Once you have found one, try it on the test set.  How much better does it perform compared to the individual classifiers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b0482ccc-bad4-4a29-9005-9497d0f6666b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 28, 28), (10000, 28, 28), (10000, 28, 28))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "train_X, val_X, train_y, val_y = train_test_split(train_X, train_y, train_size=50000)\n",
    "train_X.shape, val_X.shape, test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b96d8e53-e50f-480a-b848-feabff4302be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 784), (10000, 784), (10000, 784))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = train_X.reshape(train_X.shape[0], train_X.shape[1] * train_X.shape[2])\n",
    "val_X = val_X.reshape(val_X.shape[0], val_X.shape[1] * val_X.shape[2])\n",
    "test_X = test_X.reshape(test_X.shape[0], test_X.shape[1] * test_X.shape[2])\n",
    "train_X.shape, val_X.shape, test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b945f234-c364-41bb-8c32-cfd2c2bb9f6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.5, penalty=&#x27;l1&#x27;, solver=&#x27;saga&#x27;, tol=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.5, penalty=&#x27;l1&#x27;, solver=&#x27;saga&#x27;, tol=0.1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.5, penalty='l1', solver='saga', tol=0.1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "rnd_clf_ = RandomForestClassifier(n_estimators=100, max_depth=500, min_samples_split=5)\n",
    "scv_clf_ = SVC(C=1.0, kernel='rbf', degree=3, probability=True)\n",
    "ext_clf_ = ExtraTreesClassifier(n_estimators=100, max_depth=500, min_samples_split=5)\n",
    "log_clf_ = LogisticRegression(C=0.5, penalty=\"l1\", solver=\"saga\", tol=0.1)\n",
    "\n",
    "rnd_clf_.fit(train_X, train_y)\n",
    "scv_clf_.fit(train_X, train_y)\n",
    "ext_clf_.fit(train_X, train_y)\n",
    "log_clf_.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4921525b-8945-4ccd-a8c8-e1b4b921f638",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rnd_preds_ = rnd_clf_.predict(val_X)\n",
    "scv_preds_ = scv_clf_.predict(val_X)\n",
    "ext_preds_ = ext_clf_.predict(val_X)\n",
    "log_preds_ = log_clf_.predict(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ad2ae250-0888-4852-8e7c-442871667eb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7],\n",
       "       [1],\n",
       "       [5],\n",
       "       ...,\n",
       "       [5],\n",
       "       [1],\n",
       "       [1]], dtype=uint8)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "all_preds_ = np.array([rnd_preds_, scv_preds_, ext_preds_, log_preds_])\n",
    "hard_vote_ = stats.mode(all_preds_, keepdims=True)[0].T\n",
    "hard_vote_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6cb59dd1-459d-41b7-a5d3-bdcb64da3e5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnd: 0.9669, svc: 0.9769, ext: 0.9665, log: 0.9183, hard_vote: 0.9707\n"
     ]
    }
   ],
   "source": [
    "rnd_accuracy_score_ = accuracy_score(val_y, rnd_preds_)\n",
    "scv_accuracy_score_ = accuracy_score(val_y, scv_preds_)\n",
    "ext_accuracy_score_ = accuracy_score(val_y, ext_preds_)\n",
    "log_accuracy_score_ = accuracy_score(val_y, log_preds_)\n",
    "ensemble_accuracy_score_ = accuracy_score(val_y, hard_vote_.T)\n",
    "print(f'rnd: {rnd_accuracy_score_}, svc: {scv_accuracy_score_}, ext: {ext_accuracy_score_}, log: {log_accuracy_score_}, hard_vote: {ensemble_accuracy_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "271dacec-4338-49be-8b9f-5ca3c1caf64e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eclf1 = VotingClassifier(\n",
    "    estimators=[('rnd', rnd_clf_), ('svc', scv_clf_), ('ext', ext_clf_), ('log', log_clf_)], \n",
    "    voting='hard'\n",
    ")\n",
    "eclf1.fit(train_X, train_y)\n",
    "hard_vote_ = eclf1.predict(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "46b04d96-6b31-411d-bb03-2dd44071a0a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnd: 0.9669, svc: 0.9769, ext: 0.9665, log: 0.9183, hard_vote: 0.9697\n"
     ]
    }
   ],
   "source": [
    "rnd_accuracy_score_ = accuracy_score(val_y, rnd_preds_)\n",
    "scv_accuracy_score_ = accuracy_score(val_y, scv_preds_)\n",
    "ext_accuracy_score_ = accuracy_score(val_y, ext_preds_)\n",
    "log_accuracy_score_ = accuracy_score(val_y, log_preds_)\n",
    "ensemble_accuracy_score_ = accuracy_score(val_y, hard_vote_)\n",
    "print(f'rnd: {rnd_accuracy_score_}, svc: {scv_accuracy_score_}, ext: {ext_accuracy_score_}, log: {log_accuracy_score_}, hard_vote: {ensemble_accuracy_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a65012c9-6d77-44df-9984-dcff91884a0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eclf2 = VotingClassifier(\n",
    "    estimators=[('rnd', rnd_clf_), ('svc', scv_clf_), ('ext', ext_clf_), ('log', log_clf_)], \n",
    "    voting='soft',\n",
    "    n_jobs= -1\n",
    ")\n",
    "eclf2.fit(train_X, train_y)\n",
    "soft_vote_ = eclf2.predict(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "583e10ad-7599-4a58-9e8b-e5dda9df9d69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnd: 0.9669, svc: 0.9769, ext: 0.9665, log: 0.9183, soft_vote: 0.9703\n"
     ]
    }
   ],
   "source": [
    "rnd_accuracy_score_ = accuracy_score(val_y, rnd_preds_)\n",
    "scv_accuracy_score_ = accuracy_score(val_y, scv_preds_)\n",
    "ext_accuracy_score_ = accuracy_score(val_y, ext_preds_)\n",
    "log_accuracy_score_ = accuracy_score(val_y, log_preds_)\n",
    "ensemble_accuracy_score_ = accuracy_score(val_y, soft_vote_)\n",
    "print(f'rnd: {rnd_accuracy_score_}, svc: {scv_accuracy_score_}, ext: {ext_accuracy_score_}, log: {log_accuracy_score_}, soft_vote: {ensemble_accuracy_score_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745fa6fe-d697-46c8-a69d-fd934e01e806",
   "metadata": {},
   "source": [
    "<b> Basically what I need to do from here is use cross-validation to optimize each model.  Apply some of the concepts of the chapter like boosting, bagging, pasting, etc. to get these accuracies really tight.  And then the most likely outcome is the ensemble will outperform all models.  In the current situtation the SVC classifier is outperforming the ensemble by a little bit.  But training and optimizing these models can take hours or sometimes days and I would prefer to spend my time on other excerises and new chapters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173a20cb-200a-4744-af2e-305a1bb40f2a",
   "metadata": {},
   "source": [
    "<b> 9. Run the individual classifiers from the previous exercise to make predictions on the validation set, and create a new training set with the resulting predictions: each training instance is a vector containing the set of predictions from all your classifiers for an image, and the target is your image's class.  Train a classifier on this new training set.  Congratuations, you have just trained a blender, and together with the classifers it forms a stacking ensemble!  Now evaluate the ensemble on the test set.  For each image in the test set, make predictions with all your classifiers, then feed the predictions to the blender to get the ensemble's predictions.  How does it compare to the voting classifier you trained earlier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "63bdd9cf-c37f-4605-8cce-dd477f1a5f54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(probability=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(probability=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(probability=True)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_preds_ = np.array([rnd_preds_, scv_preds_, ext_preds_, log_preds_]).T\n",
    "svc_stack_ = SVC(C=1.0, kernel='rbf', degree=3, probability=True)\n",
    "svc_stack_.fit(val_preds_, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "93aef401-46bd-4775-b51a-3aff5dc1ecd5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stack_predictions: 0.9654\n"
     ]
    }
   ],
   "source": [
    "rnd_preds_ = rnd_clf_.predict(test_X)\n",
    "scv_preds_ = scv_clf_.predict(test_X)\n",
    "ext_preds_ = ext_clf_.predict(test_X)\n",
    "log_preds_ = log_clf_.predict(test_X)\n",
    "\n",
    "test_preds_ = np.array([rnd_preds_, scv_preds_, ext_preds_, log_preds_]).T\n",
    "stack_preds_ = svc_stack_.predict(test_preds_)\n",
    "ensemble_accuracy_score_ = accuracy_score(stack_preds_, test_y)\n",
    "print(f'stack_predictions: {ensemble_accuracy_score_}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
